{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IjFmmAEGS7E1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Anaconda navigator\\envs\\project\\lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.6 when it was built against 1.14.5, this may cause problems\n",
            "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "t1xIw7lcS7E4",
        "outputId": "2b5ce1ae-aefa-462e-cb33-d71a43bcfaed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, None, None, 256)   590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 0\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = VGG19(\n",
        "    include_top = False,\n",
        "    weights = 'imagenet'\n",
        ")\n",
        "\n",
        "model.trainable = False\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Bwee9e8_S7E_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in d:\\anaconda navigator\\envs\\project\\lib\\site-packages (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaconda navigator\\envs\\project\\lib\\site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in d:\\anaconda navigator\\envs\\project\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda navigator\\envs\\project\\lib\\site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\anaconda navigator\\envs\\project\\lib\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in d:\\anaconda navigator\\envs\\project\\lib\\site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\anaconda navigator\\envs\\project\\lib\\site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in d:\\anaconda navigator\\envs\\project\\lib\\site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anaconda navigator\\envs\\project\\lib\\site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda navigator\\envs\\project\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in d:\\anaconda navigator\\envs\\project\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "%pip install matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5vJojbKNS7FC"
      },
      "outputs": [],
      "source": [
        "def load_and_process_image(image_path):\n",
        "    img = load_img(image_path)\n",
        "    img = img_to_array(img)\n",
        "    img = preprocess_input(img)\n",
        "    img = np.expand_dims(img, axis = 0)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7Dlz472kS7FE"
      },
      "outputs": [],
      "source": [
        "def deprocess(x):\n",
        "    # perform the inverse of the preprocessiing step\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    x = x[:, :, ::-1]\n",
        "\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def display_image(image):\n",
        "    if len(image.shape) == 4:\n",
        "        img = np.squeeze(image, axis = 0)\n",
        "\n",
        "    img = deprocess(img)\n",
        "\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(img)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.1.0\n"
          ]
        }
      ],
      "source": [
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "print(PIL.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "4p3PgOlkS7FI",
        "outputId": "7f40aee3-7b25-4567-cb82-bd679ff9bd4a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in d:\\anaconda navigator\\envs\\project\\lib\\site-packages (11.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install Pillow\n",
        "\n",
        "# Ensure CELL INDEX: 3 is executed before running this cell\n",
        "img = load_and_process_image(r'C:\\Users\\Lenovo\\Downloads\\NeuralArt Style Transfer_v\\Main\\Images\\content.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure necessary imports and function definition are included\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "def load_and_process_image(image_path):\n",
        "\timg = load_img(image_path)\n",
        "\timg = img_to_array(img)\n",
        "\timg = preprocess_input(img)\n",
        "\timg = np.expand_dims(img, axis=0)\n",
        "\treturn img\n",
        "\n",
        "img = load_and_process_image(r'C:\\Users\\Lenovo\\Downloads\\NeuralArt Style Transfer_v\\Main\\Images\\content.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rfCOKVyLS7FN"
      },
      "outputs": [],
      "source": [
        "style_layers = [\n",
        "    'block1_conv1',\n",
        "    'block3_conv1',\n",
        "    'block5_conv1'\n",
        "]\n",
        "\n",
        "content_layer = 'block5_conv2'\n",
        "\n",
        "# intermediate models\n",
        "content_model = Model(\n",
        "    inputs = model.input,\n",
        "    outputs = model.get_layer(content_layer).output\n",
        ")\n",
        "\n",
        "style_models = [Model(inputs = model.input,\n",
        "                      outputs = model.get_layer(layer).output) for layer in style_layers]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "joIHQxxPS7FP"
      },
      "outputs": [],
      "source": [
        "# Content Cost\n",
        "def content_cost(content, generated):\n",
        "    a_C = content_model(content)\n",
        "    a_G = content_model(generated)\n",
        "    cost = tf.reduce_mean(tf.square(a_C - a_G))\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nCGDHH5sS7FV"
      },
      "outputs": [],
      "source": [
        "def gram_matrix(A):\n",
        "    channels = int(A.shape[-1])\n",
        "    a = tf.reshape(A, [-1, channels])\n",
        "    n = tf.shape(a)[0]\n",
        "    gram = tf.matmul(a, a, transpose_a = True)\n",
        "    return gram / tf.cast(n, tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wrF39dDrS7Fa"
      },
      "outputs": [],
      "source": [
        "lam = 1. / len(style_models)\n",
        "\n",
        "def style_cost(style, generated):\n",
        "    J_style = 0\n",
        "\n",
        "    for style_model in style_models:\n",
        "        a_S = style_model(style)\n",
        "        a_G = style_model(generated)\n",
        "        GS = gram_matrix(a_S)\n",
        "        GG = gram_matrix(a_G)\n",
        "        current_cost = tf.reduce_mean(tf.square(GS - GG))\n",
        "        J_style += current_cost * lam\n",
        "\n",
        "    return J_style"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mj48u8udS7Fd"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import tensorflow as tf  # Add this import\n",
        "\n",
        "generated_images = []\n",
        "\n",
        "def training_loop(content_path, style_path, iterations=20, a=10., b=20.):\n",
        "    # Initialise\n",
        "    content = load_and_process_image(content_path)\n",
        "    style = load_and_process_image(style_path)\n",
        "    generated = tf.Variable(content, dtype=tf.float32)\n",
        "\n",
        "    opt = tf.optimizers.Adam(learning_rate=7.0)\n",
        "\n",
        "    best_cost = float('inf')\n",
        "    best_image = None\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(iterations):\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(generated)  # Ensure gradients track changes to generated\n",
        "            J_content = content_cost(content, generated)\n",
        "            J_style = style_cost(style, generated)\n",
        "            J_total = a * J_content + b * J_style  # Ensure J_content and J_style are scalars\n",
        "\n",
        "        grads = tape.gradient(J_total, generated)\n",
        "        # Fix: Pass generated directly instead of wrapping it in a list\n",
        "        opt.apply_gradients([(grads, generated)])\n",
        "\n",
        "        if J_total < best_cost:\n",
        "            best_cost = J_total\n",
        "            best_image = generated.numpy()\n",
        "\n",
        "        if i % (iterations // 10) == 0:\n",
        "            time_taken = time.time() - start_time\n",
        "            print(f'Cost at iteration {i}: {J_total.numpy():.4f}. Time elapsed: {time_taken:.2f}s')\n",
        "            generated_images.append(generated.numpy())\n",
        "\n",
        "    return best_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVVskySYS7Ff",
        "outputId": "1b2007e3-f1a3-461b-d512-b7dda7689f2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cost at iteration 0: 10381280256.0000. Time elapsed: 4.69s\n",
            "Cost at iteration 2: 4323870720.0000. Time elapsed: 12.77s\n",
            "Cost at iteration 4: 2762459648.0000. Time elapsed: 26.98s\n",
            "Cost at iteration 6: 2271082496.0000. Time elapsed: 39.01s\n",
            "Cost at iteration 8: 1823080192.0000. Time elapsed: 47.37s\n",
            "Cost at iteration 10: 1460318208.0000. Time elapsed: 56.23s\n",
            "Cost at iteration 12: 1172826112.0000. Time elapsed: 65.24s\n",
            "Cost at iteration 14: 984187008.0000. Time elapsed: 73.69s\n",
            "Cost at iteration 16: 852929152.0000. Time elapsed: 83.28s\n",
            "Cost at iteration 18: 747446592.0000. Time elapsed: 92.84s\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "final = training_loop(\n",
        "\tr'C:\\Users\\Lenovo\\Downloads\\NeuralArt Style Transfer_v\\Main\\Images\\content.png',\n",
        "\tr'C:\\Users\\Lenovo\\Downloads\\NeuralArt Style Transfer_v\\Main\\Images\\style.png'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: The variable 'final' is not defined. Please execute the cell that defines 'final' (CELL INDEX: 14) first.\n"
          ]
        }
      ],
      "source": [
        "# Ensure CELL INDEX: 14 is executed before running this cell\n",
        "try:\n",
        "\t# Display the final generated image\n",
        "\tdisplay_image(final)\n",
        "except NameError:\n",
        "\tprint(\"Error: The variable 'final' is not defined. Please execute the cell that defines 'final' (CELL INDEX: 14) first.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
